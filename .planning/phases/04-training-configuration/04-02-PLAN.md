---
phase: 04-training-configuration
plan: 02
type: execute
wave: 2
depends_on: ["04-01"]
files_modified:
  - src/classifier_training/callbacks/confusion_matrix.py
  - tests/test_train_config.py
autonomous: true

must_haves:
  truths:
    - "ConfusionMatrixCallback logs PNG images to WandB when WandbLogger is active"
    - "Hydra config override model=resnet50 changes the instantiated model class"
    - "Hydra config override data.batch_size=32 changes the DataModule batch size"
    - "Trainer config has precision=16-mixed, gradient_clip_val=1.0, accumulate_grad_batches=1"
    - "Config composition resolves all 5 defaults groups without error"
  artifacts:
    - path: "tests/test_train_config.py"
      provides: "Tests for Hydra config composition, overrides, instantiation, and WandB logging"
    - path: "src/classifier_training/callbacks/confusion_matrix.py"
      provides: "WandB image logging in on_validation_epoch_end"
  key_links:
    - from: "src/classifier_training/callbacks/confusion_matrix.py"
      to: "lightning.pytorch.loggers.WandbLogger"
      via: "isinstance check + log_image call"
      pattern: "isinstance.*WandbLogger.*log_image"
    - from: "tests/test_train_config.py"
      to: "src/classifier_training/conf/train_basketball_resnet18.yaml"
      via: "Hydra compose for config tests"
      pattern: "compose.*train_basketball_resnet18"
---

<objective>
Add WandB image logging to ConfusionMatrixCallback and write comprehensive tests for Hydra config composition, overrides, and component instantiation.

Purpose: Validates that the config wiring from Plan 04-01 actually works end-to-end and adds the WandB confusion matrix logging required by TRAIN-05.
Output: Updated confusion_matrix.py with WandB logging, test_train_config.py test suite.
</objective>

<execution_context>
@/Users/ortizeg/.claude/get-shit-done/workflows/execute-plan.md
@/Users/ortizeg/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-training-configuration/04-RESEARCH.md
@.planning/phases/04-training-configuration/04-01-SUMMARY.md

# Source files
@src/classifier_training/callbacks/confusion_matrix.py
@src/classifier_training/train.py
@src/classifier_training/conf/train_basketball_resnet18.yaml
</context>

<tasks>

<task type="auto">
  <name>Task 1: WandB image logging in ConfusionMatrixCallback</name>
  <files>
    src/classifier_training/callbacks/confusion_matrix.py
  </files>
  <action>
Two changes to `ConfusionMatrixCallback`:

**1. Refactor `_plot_and_save` to return the saved Path:**

Change the method signature from `-> None` to `-> Path`:

```python
def _plot_and_save(self, cm: torch.Tensor, epoch: int) -> Path:
    """Render confusion matrix as a heatmap and save to disk."""
    # ... existing body unchanged ...
    logger.info(f"Confusion matrix saved to {save_path}")
    return save_path  # ADD this return statement
```

**2. Add WandB image logging in `on_validation_epoch_end`:**

```python
# At top of file, add import:
from lightning.pytorch.loggers import WandbLogger

# In on_validation_epoch_end, change:
#   self._plot_and_save(cm_tensor, epoch)
# to:
png_path = self._plot_and_save(cm_tensor, epoch)

# Log confusion matrix image to WandB if WandbLogger is active
if png_path.exists():
    for lgr in trainer.loggers:
        if isinstance(lgr, WandbLogger):
            lgr.log_image(
                key="confusion_matrix",
                images=[str(png_path)],
                step=trainer.current_epoch,
            )
            logger.debug(f"Logged confusion matrix to WandB (epoch {epoch})")
```

Key points:
- `_plot_and_save` now returns the `Path` — eliminates path duplication between methods.
- `png_path.exists()` guard prevents `log_image` from failing if file save failed for any reason.
- `WandbLogger.log_image()` accepts file path strings — no need to import `wandb` directly.
- Use `isinstance` guard so callback works with or without WandB (graceful degradation).
- Use `trainer.loggers` (list), not `trainer.logger` (single), to handle multiple loggers.
  </action>
  <verify>
1. `pixi run lint` passes (ruff on confusion_matrix.py)
2. `pixi run typecheck` passes
3. All existing tests still pass: `pixi run test`
  </verify>
  <done>
ConfusionMatrixCallback logs confusion matrix PNGs to WandB when a WandbLogger is present. Callback still works without WandB (isinstance guard). No changes to existing API.
  </done>
</task>

<task type="auto">
  <name>Task 2: Hydra config composition and override tests</name>
  <files>
    tests/test_train_config.py
  </files>
  <action>
Create `tests/test_train_config.py` with tests validating Phase 4 config wiring. Use `hydra.compose` with `initialize_config_dir` for config-only tests (no file I/O needed, no training run).

**Test 1: `test_hydra_config_composes`** — Root config loads without error; all 5 defaults resolve (model, data, trainer, callbacks, logging).
```python
from hydra import compose, initialize_config_dir
import os

def test_hydra_config_composes():
    conf_dir = os.path.abspath("src/classifier_training/conf")
    with initialize_config_dir(config_dir=conf_dir, version_base=None):
        cfg = compose(config_name="train_basketball_resnet18")
        assert "model" in cfg
        assert "data" in cfg
        assert "trainer" in cfg
        assert "callbacks" in cfg
        assert "logging" in cfg
```

**Test 2: `test_trainer_config_values`** — Verify T4 defaults (TRAIN-02, TRAIN-03, TRAIN-04):
```python
def test_trainer_config_values():
    # ... compose config ...
    assert cfg.trainer.precision == "16-mixed"      # TRAIN-02
    assert cfg.trainer.gradient_clip_val == 1.0      # TRAIN-03
    assert cfg.trainer.accumulate_grad_batches == 1  # TRAIN-03
    assert cfg.trainer.max_epochs == 100
    assert cfg.trainer.accelerator == "auto"
```

**Test 3: `test_data_config_values`** — Verify basketball dataset defaults (TRAIN-04, TRAIN-06):
```python
def test_data_config_values():
    # ... compose config ...
    assert cfg.data.batch_size == 64                 # TRAIN-04
    assert cfg.data.num_workers == 4                 # TRAIN-04
    assert "basketball-jersey-numbers-ocr" in cfg.data.data_root  # TRAIN-06
    assert cfg.data.image_size == 224
```

**Test 4: `test_data_config_instantiates`** — `hydra.utils.instantiate(cfg.data)` produces `ImageFolderDataModule`:
```python
import hydra.utils
from classifier_training.data.datamodule import ImageFolderDataModule

def test_data_config_instantiates():
    # ... compose config ...
    dm = hydra.utils.instantiate(cfg.data)
    assert isinstance(dm, ImageFolderDataModule)
```

**Test 5: `test_model_config_instantiates`** — `hydra.utils.instantiate(cfg.model)` produces correct model:
```python
import classifier_training.models  # noqa: F401 — trigger @register
from classifier_training.models.resnet import ResNet18ClassificationModel

def test_model_config_instantiates():
    # ... compose config ...
    model = hydra.utils.instantiate(cfg.model, pretrained=False)
    assert isinstance(model, ResNet18ClassificationModel)
```

Use `pretrained=False` override to avoid downloading weights in tests.

**Test 6: `test_hydra_override_model`** — `model=resnet50` override works (Phase 4 success criterion 5):
```python
from classifier_training.models.resnet import ResNet50ClassificationModel

def test_hydra_override_model():
    # ... compose with overrides=["model=resnet50"] ...
    model = hydra.utils.instantiate(cfg.model, pretrained=False)
    assert isinstance(model, ResNet50ClassificationModel)
```

**Test 7: `test_hydra_override_batch_size`** — `data.batch_size=32` override propagates (Phase 4 success criterion 5):
```python
def test_hydra_override_batch_size():
    # ... compose with overrides=["data.batch_size=32"] ...
    assert cfg.data.batch_size == 32
    dm = hydra.utils.instantiate(cfg.data)
    assert dm._config.batch_size == 32
```

**Test 8: `test_checkpoint_resume_path_resolves_stably`** — ModelCheckpoint dirpath is fixed AND train.py sets default_root_dir for stable resolution:
```python
import ast
from pathlib import Path

def test_checkpoint_resume_path_resolves_stably():
    # ... compose config ...
    # 1. Verify config value is fixed (not timestamped)
    ckpt_cfg = cfg.callbacks.model_checkpoint
    assert ckpt_cfg.dirpath == "checkpoints"  # Fixed, not ${hydra:runtime.output_dir}
    assert "${" not in str(ckpt_cfg.dirpath)  # No Hydra interpolation

    # 2. Verify train.py sets default_root_dir (so "checkpoints" resolves stably)
    train_src = Path("src/classifier_training/train.py").read_text()
    assert "default_root_dir" in train_src, "train.py must set default_root_dir for stable checkpoint resolution"
    assert "HydraConfig.get().runtime.cwd" in train_src, "default_root_dir should use original cwd, not Hydra output dir"
```

This test validates the end-to-end resume path: `Trainer(default_root_dir=cwd)` + `ModelCheckpoint(dirpath="checkpoints")` = `{cwd}/checkpoints` — stable across runs.

**Test 9: `test_wandb_logger_config`** — WandbLogger config present in composed config:
```python
def test_wandb_logger_config():
    # ... compose config ...
    assert "wandb" in cfg.logging
    assert cfg.logging.wandb._target_ == "lightning.pytorch.loggers.WandbLogger"
    assert cfg.logging.wandb.project == "classifier-training"
```

**Test 10: `test_seed_and_log_level`** — Global params from root config:
```python
def test_seed_and_log_level():
    # ... compose config ...
    assert cfg.seed == 42
    assert cfg.log_level == "INFO"
```

**Test 11: `test_wandb_metric_routing_documented`** — Verify WandbLogger is correctly wired so `self.log()` metrics flow to WandB:
```python
def test_wandb_metric_routing_documented():
    """Verify WandbLogger config is correct for metric routing.

    NOTE: self.log() -> WandbLogger metric routing is handled by Lightning's
    built-in WandbLogger integration. When WandbLogger is passed to Trainer(logger=...),
    all self.log() calls in LightningModule automatically route to wandb.log().
    This is a Lightning framework guarantee, not custom code.

    This test verifies the config prerequisites are correct (logger target and project).
    """
    # ... compose config ...
    wandb_cfg = cfg.logging.wandb
    assert wandb_cfg._target_ == "lightning.pytorch.loggers.WandbLogger"
    # WandbLogger's __init__ accepts project, which Lightning uses for wandb.init()
    assert wandb_cfg.project == "classifier-training"
    # log_model=false prevents auto-uploading model artifacts (we handle ONNX export separately)
    assert wandb_cfg.log_model is False
```

**Important patterns:**
- Use a pytest fixture for `initialize_config_dir` + `compose` to avoid Hydra GlobalHydra already initialized errors. Use `GlobalHydra.instance().clear()` in fixture teardown OR use `hydra.core.global_hydra.GlobalHydra.instance().clear()` before each test.
- Import `classifier_training.models` to trigger @register decorators before model instantiation tests.
- Use `pretrained=False` for model instantiation to avoid weight downloads.
- The config group directory names MUST match what Plan 04-01 created (singular `model/`, not plural `models/`) — verify by reading the actual YAML files if uncertain.
  </action>
  <verify>
1. `pixi run test tests/test_train_config.py -v` — all 11 tests pass
2. `pixi run test` — all tests pass (90 existing + 11 new = ~101)
3. `pixi run lint` and `pixi run typecheck` pass
  </verify>
  <done>
11 tests validate: config composition, trainer T4 defaults (precision, clipping, accumulation), data config values, model/data instantiation via Hydra, model override (resnet50), batch_size override, fixed checkpoint dirpath, WandB logger config, global seed/log_level. All tests pass alongside existing 90 tests.
  </done>
</task>

</tasks>

<verification>
1. `pixi run test` — all tests pass (~100 total)
2. `pixi run lint && pixi run typecheck` — clean
3. ConfusionMatrixCallback has WandB logging (grep for `WandbLogger` in confusion_matrix.py)
4. Config override `model=resnet50` produces ResNet50 (tested)
5. Config override `data.batch_size=32` propagates (tested)
6. ModelCheckpoint dirpath is fixed `checkpoints` (tested)
</verification>

<success_criteria>
- ConfusionMatrixCallback logs images to WandB when WandbLogger active
- 11 config tests all pass
- Hydra overrides work for model and batch_size
- Trainer config has correct T4 defaults
- Total test count ~100 (90 existing + ~11 new)
</success_criteria>

<output>
After completion, create `.planning/phases/04-training-configuration/04-02-SUMMARY.md`
</output>
